{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75e363bc-4eb3-4240-8fa5-e9b290a660d9",
   "metadata": {},
   "source": [
    "# Data cleaning\n",
    "\n",
    "As menthioned in the exploratory analysis notebook, we'll be using a subset of the original dataset (includes data for 45 taxis for the entire year) for subsequent studies. We'll first clean the data.\n",
    "\n",
    "### Load the dataset\n",
    "First let's take a quick look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5e9804b9-7c5e-4e7b-a451-3cb77da2039b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>CALL_TYPE</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>DAY_TYPE</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "      <th>POLYLINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1372636875620000233</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000233</td>\n",
       "      <td>1372636875</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.619894,41.148009],[-8.620164,41.14773],[-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1372638595620000233</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000233</td>\n",
       "      <td>1372638595</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.608716,41.153499],[-8.607627,41.153481],[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1372639092620000233</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000233</td>\n",
       "      <td>1372639092</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.632737,41.168295],[-8.6328,41.16825],[-8....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1372641600620000612</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20000612</td>\n",
       "      <td>1372641600</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.585811,41.148666],[-8.585757,41.148972],[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1372636896620000360</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000360</td>\n",
       "      <td>1372636896</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.617599,41.146137],[-8.617581,41.14593],[-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                TRIP_ID CALL_TYPE  ORIGIN_CALL  ORIGIN_STAND   TAXI_ID  \\\n",
       "10  1372636875620000233         C          NaN           NaN  20000233   \n",
       "13  1372638595620000233         C          NaN           NaN  20000233   \n",
       "25  1372639092620000233         C          NaN           NaN  20000233   \n",
       "63  1372641600620000612         B          NaN          15.0  20000612   \n",
       "64  1372636896620000360         C          NaN           NaN  20000360   \n",
       "\n",
       "     TIMESTAMP DAY_TYPE  MISSING_DATA  \\\n",
       "10  1372636875        A         False   \n",
       "13  1372638595        A         False   \n",
       "25  1372639092        A         False   \n",
       "63  1372641600        A         False   \n",
       "64  1372636896        A         False   \n",
       "\n",
       "                                             POLYLINE  \n",
       "10  [[-8.619894,41.148009],[-8.620164,41.14773],[-...  \n",
       "13  [[-8.608716,41.153499],[-8.607627,41.153481],[...  \n",
       "25  [[-8.632737,41.168295],[-8.6328,41.16825],[-8....  \n",
       "63  [[-8.585811,41.148666],[-8.585757,41.148972],[...  \n",
       "64  [[-8.617599,41.146137],[-8.617581,41.14593],[-...  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_raw = pd.read_pickle('subset_data.pkl')\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82da6aed-74aa-43eb-839d-e5619cd9e5ab",
   "metadata": {},
   "source": [
    "### Missing data\n",
    "First, we look for rows/entries that contain missing data. The columns 'ORIGIN_CALL' and 'ORIGIN_STAND' contains nan values by definition, so we'll look in columns other than these two. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6ad72fd4-35c5-4792-a076-419ded2c7b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get list of all column names\n",
    "column_names = list(df_raw.columns)\n",
    "# Generate list of all column names except for 'ORIGIN_CALL' and 'ORIGIN_STAND'\n",
    "filtered_names = [s for s in column_names if s not in ['ORIGIN_CALL', 'ORIGIN_STAND']]\n",
    "\n",
    "# Get rows that contain missing data\n",
    "missing_data_rows = df_raw[df_raw[filtered_names].isna().any(axis=1)]\n",
    "len(missing_data_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecbd909-75f9-4fd6-aae7-8852a4e75148",
   "metadata": {},
   "source": [
    "### Check data format and data type\n",
    "We can see that there's no rows that contain missing data. Next, let's examine the data to make sure all data are in the correct format or data type. Looking at the summary, and reading the dataset description, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e0cd0f45-6297-4846-ac3c-84e17a54f0ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 179932 entries, 10 to 1710666\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   TRIP_ID       179932 non-null  int64  \n",
      " 1   CALL_TYPE     179932 non-null  object \n",
      " 2   ORIGIN_CALL   37869 non-null   float64\n",
      " 3   ORIGIN_STAND  84877 non-null   float64\n",
      " 4   TAXI_ID       179932 non-null  int64  \n",
      " 5   TIMESTAMP     179932 non-null  int64  \n",
      " 6   DAY_TYPE      179932 non-null  object \n",
      " 7   MISSING_DATA  179932 non-null  bool   \n",
      " 8   POLYLINE      179932 non-null  object \n",
      "dtypes: bool(1), float64(2), int64(3), object(3)\n",
      "memory usage: 12.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd64d451-b628-4ea4-a9c8-854fe564a66d",
   "metadata": {},
   "source": [
    "We can see that columns   \n",
    "'TRIP_ID', 'TAXI_ID', 'TIMESTAMP' should be int type,  \n",
    "'CALL_TYPE' and 'DAY_TYPE' should take in one of these three values ['A', 'B', 'C'],  \n",
    "'ORIGIN_CALL' and 'ORIGIN_STAND' should be float type (the NULL value is represented by _np.nan_, which is also _float_ type),    \n",
    "'MISSING_DATA' should be bool type,  \n",
    "'POLYLINE' should be str type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "27bd6266-7046-4e83-b5fa-e150eb67a5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rows that contain data in incorrect type\n",
    "# use df.apply and lambda function to check if data in current row is the correct type\n",
    "incorrect_entries = []\n",
    "incorrect_entries.append(df_raw[~df_raw['TRIP_ID'].apply(lambda x: isinstance(x, int))])\n",
    "incorrect_entries.append(df_raw[~df_raw['TAXI_ID'].apply(lambda x: isinstance(x, int))])\n",
    "incorrect_entries.append(df_raw[~df_raw['TIMESTAMP'].apply(lambda x: isinstance(x, int))])\n",
    "\n",
    "incorrect_entries.append(df_raw[~df_raw['CALL_TYPE'].isin(['A', 'B', 'C'])])\n",
    "incorrect_entries.append(df_raw[~df_raw['DAY_TYPE'].isin(['A', 'B', 'C'])])\n",
    "\n",
    "incorrect_entries.append(df_raw[~df_raw['ORIGIN_CALL'].apply(lambda x: isinstance(x, float))])\n",
    "incorrect_entries.append(df_raw[~df_raw['ORIGIN_STAND'].apply(lambda x: isinstance(x, float))])\n",
    "\n",
    "incorrect_entries.append(df_raw[~df_raw['MISSING_DATA'].apply(lambda x: isinstance(x, bool))])\n",
    "incorrect_entries.append(df_raw[~df_raw['POLYLINE'].apply(lambda x: isinstance(x, str))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "cf9fa8ff-b5f7-46bc-9c2a-bce4ebfa34c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_incorrect_entries = [len(d) for d in incorrect_entries]\n",
    "size_incorrect_entries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072dd5ea-ebf0-44ac-9c05-d286742f9f0b",
   "metadata": {},
   "source": [
    "### GPS coordinates data\n",
    "We can see that all data are in correct data type. Next, we want to remove POLYLINE data that doesn't have practical meaning, which are POLYLINE data that doesn't contain any GPS coordinates, or contains only one coordinate. The POLYLINE data is a string in this format: '[[LONGITUDE, LATITUDE],[LONGITUDE, LATITUDE],...]]', note that the GPS coordinates has a precision of six decimal places, so the longest lenght of a POLYLINE string with one coordinate is 25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "63def85d-0de4-40e6-be0c-5b4255fe8e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>CALL_TYPE</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>DAY_TYPE</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "      <th>POLYLINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1708287</th>\n",
       "      <td>1404139515620000432</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000432</td>\n",
       "      <td>1404139515</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.644968,41.158647]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1708464</th>\n",
       "      <td>1404139454620000188</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000188</td>\n",
       "      <td>1404139454</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.659098,41.160402]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709057</th>\n",
       "      <td>1404148899620000129</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>20000129</td>\n",
       "      <td>1404148899</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.613918,41.141142]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710413</th>\n",
       "      <td>1404107068620000618</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000618</td>\n",
       "      <td>1404107068</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.526681,41.164506]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710643</th>\n",
       "      <td>1386603894620000970</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000970</td>\n",
       "      <td>1386603894</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     TRIP_ID CALL_TYPE  ORIGIN_CALL  ORIGIN_STAND   TAXI_ID  \\\n",
       "1708287  1404139515620000432         C          NaN           NaN  20000432   \n",
       "1708464  1404139454620000188         C          NaN           NaN  20000188   \n",
       "1709057  1404148899620000129         B          NaN          53.0  20000129   \n",
       "1710413  1404107068620000618         C          NaN           NaN  20000618   \n",
       "1710643  1386603894620000970         C          NaN           NaN  20000970   \n",
       "\n",
       "          TIMESTAMP DAY_TYPE  MISSING_DATA                 POLYLINE  \n",
       "1708287  1404139515        A         False  [[-8.644968,41.158647]]  \n",
       "1708464  1404139454        A         False  [[-8.659098,41.160402]]  \n",
       "1709057  1404148899        A         False  [[-8.613918,41.141142]]  \n",
       "1710413  1404107068        A         False  [[-8.526681,41.164506]]  \n",
       "1710643  1386603894        A         False                       []  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polyline_records_to_remove = df_raw[df_raw['POLYLINE'].apply(len) <= 25]\n",
    "polyline_records_to_remove.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c9ab22ac-527c-4b3f-9f70-2e18044a6c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 5267 rows.\n"
     ]
    }
   ],
   "source": [
    "# Remove entries from the raw data where the POLYLINE column is not meaningful\n",
    "df = df_raw[df_raw['POLYLINE'].apply(len) > 25]\n",
    "\n",
    "print(\"Removed {} rows.\".format(len(polyline_records_to_remove)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd3260a-8541-41eb-8ab5-a2215fb2922d",
   "metadata": {},
   "source": [
    "### Remove duplicates\n",
    "Next, we remove duplicated rows in the dataset. Apart from finding duplicated rows, we also need to find duplicates in trip ID since it should be an unique identifier for each trip. Also, it is impossible for one taxi to start two trips at the same time, so we need to find rows that have duplicated values in taxi ID and timestamp simultaneously. It's unlikely for two trips to have exactly the same list GPS coordinates, so we should also remove duplicates in POLYLINE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "024e68df-500e-4436-9a32-b7a54dc6b1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find all occurrences of duplicate rows (including the first one)\n",
    "all_duplicates = df[df.duplicated(keep=False)]\n",
    "len(all_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d81053b0-7478-4a89-88b2-c3f997e48075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all duplicates in trip ID\n",
    "duplicates_tripid = df[df['TRIP_ID'].duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "229044c6-5503-4228-b438-45649fe0e72b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>CALL_TYPE</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>DAY_TYPE</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "      <th>POLYLINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1145967</th>\n",
       "      <td>1394118360620000066</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000066</td>\n",
       "      <td>1394118360</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.633178,41.163867],[-8.633583,41.163318]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146242</th>\n",
       "      <td>1394118360620000066</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000066</td>\n",
       "      <td>1394118360</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.633565,41.163309],[-8.633241,41.16285],[-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357574</th>\n",
       "      <td>1398185157620000066</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000066</td>\n",
       "      <td>1398185157</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.637525,41.159394],[-8.637246,41.159277]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357714</th>\n",
       "      <td>1398185157620000066</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000066</td>\n",
       "      <td>1398185157</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.636715,41.159187],[-8.636031,41.159106],[...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     TRIP_ID CALL_TYPE  ORIGIN_CALL  ORIGIN_STAND   TAXI_ID  \\\n",
       "1145967  1394118360620000066         C          NaN           NaN  20000066   \n",
       "1146242  1394118360620000066         C          NaN           NaN  20000066   \n",
       "1357574  1398185157620000066         C          NaN           NaN  20000066   \n",
       "1357714  1398185157620000066         C          NaN           NaN  20000066   \n",
       "\n",
       "          TIMESTAMP DAY_TYPE  MISSING_DATA  \\\n",
       "1145967  1394118360        A         False   \n",
       "1146242  1394118360        A         False   \n",
       "1357574  1398185157        A         False   \n",
       "1357714  1398185157        A         False   \n",
       "\n",
       "                                                  POLYLINE  \n",
       "1145967      [[-8.633178,41.163867],[-8.633583,41.163318]]  \n",
       "1146242  [[-8.633565,41.163309],[-8.633241,41.16285],[-...  \n",
       "1357574      [[-8.637525,41.159394],[-8.637246,41.159277]]  \n",
       "1357714  [[-8.636715,41.159187],[-8.636031,41.159106],[...  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates_tripid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727a2453-50cc-4b0b-9da8-b1453a5a1928",
   "metadata": {},
   "source": [
    "There're two pairs of duplicates in trip ID. By examining each pair, we can see that for the first pair of data, the first entry includes POLYLINE that only has two GPS coordinates, while the other entry includes GPS coordinates of a complete trip. Therefore, we can keep only the second entry as the data for this trip ID. Similarly, we also keep the second entry for the second pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "cb4a55b9-2c5a-4b30-ba36-e27f4bd79108",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove desired rows\n",
    "df = df.drop([list(duplicates_tripID.index)[0], list(duplicates_tripID.index)[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a022b0-9c5e-4200-890b-aa86ecdb7678",
   "metadata": {},
   "source": [
    "Remove duplicates in POLYLINE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3a0002c8-1ce7-4aec-a3cf-3eddce197b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find all duplicates in POLYLINE\n",
    "duplicates_polyline = df[df['POLYLINE'].duplicated(keep=False)]\n",
    "len(duplicates_polyline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26a5927-799c-4c19-8a28-fe511e952028",
   "metadata": {},
   "source": [
    "By carefully examining these data, we can see that the duplicates of a POLYLINE is made by the same taxi on different timestamps. We can keep the first entry of the duplicated entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b4d517c4-85c9-4797-92ff-1cd400004ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset='POLYLINE', keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89febae8-c4c2-4c20-a0a8-035fc93cc0af",
   "metadata": {},
   "source": [
    "Find duplicates in taxi ID and timestamp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1c60a830-5ae7-48e0-947c-704266b7ad0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find duplicates in taxi ID and timestamp\n",
    "duplicates_taxiid_timestamp = df[df.duplicated(subset=['TAXI_ID', 'TIMESTAMP'], keep=False)]\n",
    "len(duplicates_taxiid_timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211fd9de-85bd-4722-935e-8dd8f36bf15a",
   "metadata": {},
   "source": [
    "### Missing data in GPS coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9e75d12e-23ab-4a19-8395-3d0038010ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many entries of GPS data stream have one (or more) locations that are missing\n",
    "true_count = len(df[df['MISSING_DATA'] == True])\n",
    "true_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1270fbd4-00af-41c7-ae7a-cb2469b53eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>CALL_TYPE</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>DAY_TYPE</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "      <th>POLYLINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105621</th>\n",
       "      <td>1374554455620000625</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>20000625</td>\n",
       "      <td>1374554455</td>\n",
       "      <td>A</td>\n",
       "      <td>True</td>\n",
       "      <td>[[-8.612559,41.145975],[-8.612577,41.145975],[...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    TRIP_ID CALL_TYPE  ORIGIN_CALL  ORIGIN_STAND   TAXI_ID  \\\n",
       "105621  1374554455620000625         B          NaN          23.0  20000625   \n",
       "\n",
       "         TIMESTAMP DAY_TYPE  MISSING_DATA  \\\n",
       "105621  1374554455        A          True   \n",
       "\n",
       "                                                 POLYLINE  \n",
       "105621  [[-8.612559,41.145975],[-8.612577,41.145975],[...  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_missing_GPS_data = df[df['MISSING_DATA'] == True]\n",
    "row_missing_GPS_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36252630-9068-4f5a-91f6-bc3ead519316",
   "metadata": {},
   "source": [
    "### Save relevant data\n",
    "To improve efficiency and reduce computational overhead, we will save only the columns that are relevant for the next steps in our study, which is trip ID (we'll use this as the unique identifier for each trip) and POLYLINE.   \n",
    "Since all entries in 'MISSING_DATA' takes the value FALSE except for one, we'll remove this column, and keep the index of the entry with missing GPS coordinates for later reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "fd12c2db-1e62-4a70-bc59-d6f4045abcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index of the row that has missing GPS coordinates\n",
    "index_missing_GPS_data = list(row_missing_GPS_data.index)[0]\n",
    "\n",
    "# Save only 'TRIP_ID' and 'POLYLINE' column\n",
    "df_clean = df[['TRIP_ID', 'POLYLINE']]\n",
    "\n",
    "# Save the cleaned data as .pkl file\n",
    "df_clean.to_pickle('clean_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b39383-b069-4507-8059-e760e91d2b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
